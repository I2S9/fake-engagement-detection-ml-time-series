{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Interpretability & Risk ML Dashboard\n",
    "\n",
    "This notebook provides interpretability analysis and risk monitoring dashboard:\n",
    "- Feature importance analysis\n",
    "- SHAP values for model explanations\n",
    "- Risk monitoring and alerting\n",
    "- Dashboard metrics\n",
    "\n",
    "Essential for Risk ML pipeline and fraud detection systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline",
    "import sys",
    "from pathlib import Path",
    "from datetime import datetime, timedelta",
    "# add project root to pathproject_root = Path().resolve().parentsys.path.insert(0, str(project_roo",
    "t))",
    "# create output directory for plotsoutput_dir = project_root / \"outputs\" / \"figures\"output_dir.mkdir(parents = True, exist_ok = Tru",
    "e)",
    "import pandas as pd",
    "import numpy as np",
    "import matplotlib.pyplot as plt",
    "import seaborn as sns",
    "import warningswarnings.filterwarnings('ignore')",
    "# set plotting styl",
    "e",
    "try: plt.style.use('seaborn-v0_8-darkgrid')",
    "except OSError: try: plt.style.use('seaborn-darkgrid') except OSError: plt.style.use('default')",
    "sns.set_palette(\"husl\")",
    "plt.rcParams['figure.figsize'] = (14, 8)",
    "plt.rcParams['font.size'] = 10",
    "plt.rcParams['axes.labelsize'] = 12",
    "plt.rcParams['axes.titlesize'] = 14",
    "plt.rcParams['figure.dpi'] = 100",
    "plt.rcParams['savefig.dpi'] = 150",
    "plt.rcParams['savefig.bbox'] = 'tight'# import project module",
    "s",
    "from src.data.load_data import load_data",
    "from src.features.temporal_features import extract_temporal_features",
    "from src.interpretability.explain impor",
    "t(compute_feature_",
    "importance, compute_shap_values, explain_prediction, plot_feature_",
    "importance)",
    "from src.monitoring.risk_dashboard import RiskMonitor",
    "from sklearn.ensemble import RandomForestClass",
    "if ier",
    "from sklearn.model_selection import train_test_split",
    "from sklearn.preprocessing import StandardScaler",
    "from sklearn.metrics import roc_auc_score, precision_score, recall_score, f1_score",
    "# import IPython displa",
    "y",
    "try: from IPython.display import Image, display HAS_IPYTHON = True",
    "except ImportError: HAS_IPYTHON = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Train Model for Interpretability\n",
    "\n",
    "Load data, extract features, and train a model for interpretability analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load datasetdata_path = project_root / \"data\" / \"raw\" / \"engagement.parquet\"df = load_data(data_pat",
    "h)",
    "# adapt column name",
    "s",
    "if 'user_id' in df.columns and 'id' not in df.columns: df['id'] = df['user_id']",
    "if 'is_fake_series' in df.columns and 'label' not in df.columns: df['label'] = df['is_fake_series'].ma",
    "p({True: 'fake', False: 'normal'})",
    "print(f\"Dataset shape: {df.shape}\")",
    "print(f\"Label distribution:\")",
    "print(df['label'].value_counts())# extract.features",
    "print(\"\\nExtracting temporal features...\")features_df = extract_temporal_feature",
    "s(df, id_column = \"id\", timestamp_column = \"timestamp\", window_sizes = [6, 12, 24], autocorr_lags = [1, 6, 12, 24], aggregate_per_id = True,)",
    "print(f\"Features extracted: {features_df.shape}\")# prepare for modelingfeature_cols = [c for c in features_df.columns if c not in ['id', 'label']]X = features_df[",
    "feature_cols].fillna(0)y = features_df['label'].map({'normal': 0, 'fake': 1}).values",
    "# train / test splitX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42, stra",
    "t",
    "if y = y)",
    "# standardizescaler = StandardScaler()X_train_scaled = scaler.fit_transform(X_train)X_test_scaled = scaler.transform(X_tes",
    "t)",
    "# train Random Forest for.interpretabilit",
    "y",
    "print(\"\\nTraining Random Forest model...\")rf_model = RandomForestClassif ier(n_estimators = 100, random_state = 42, n_jobs =  - 1)rf_model.fi",
    "t(X_train_scaled, y_train)",
    "print(f\"Training accuracy: {rf_model.score(X_train_scaled, y_train):.4f}\")",
    "print(f\"Test accuracy: {rf_model.score(X_test_scaled, y_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Importance Analysis\n",
    "\n",
    "Identify which features are most important for detecting fake engagement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute feature importanceimportance_dict = compute_feature_importance(rf_model, pd.DataFrame(X_train_scaled, columns = feature_cols), y_train, feature_names = ",
    "feature_cols, method = \"permutation\")",
    "# plot feature importancefig, ax = plot_featur",
    "e_",
    "importance(importance_dict, top_k = 20, title = \"Top 20 Most Important Features for Fake Engagement Detection\")",
    "plt.savefig(output_dir / \"05_feature_",
    "importance.png\", dpi = 150, bbox_inches = 'tight')",
    "plt.show()",
    "if HAS_IPYTHON and(output_dir / \"05_feature_",
    "importance.png\").exists(): display(Image(str(output_dir / \"05_feature_",
    "importance.png\")))",
    "# print top.feature",
    "s",
    "print(\"\\nTop 10 Most Important Features:\")top_features = sorted(importance_dict.items(), key = lambda x: x[1], reverse = True)[:10] for idx, (feature, importance) in enumerate(top_features, 1): prin",
    "t(f\" {idx}. {feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Risk Monitoring Dashboard\n",
    "\n",
    "Monitor alerts, track metrics, and generate risk reports.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize risk monitorrisk_monitor = RiskMonitor(alert_threshold = 0.7, alert_window_hour",
    "s = 24)",
    "# simulate predictions and generate alertsy_proba = rf_model.predict_proba(X_test_scale",
    "d)[:, 1]",
    "# generate alerts for high - risk predictionsalerts_generated = 0 for idx in range(len(X_test)): score = y_proba[idx] user_id = str(features_df.iloc[X_test.index[idx]]['id']) if.hasattr(X_test, 'index') and X_test.index[idx] < len(features_df) else f\"user_{idx}\" timestamp = datetime.now() - timedelta(hours = len(X_test) - idx) if risk_monitor.check_alert(user_id, score, timestamp, {\"true_label\": int(y_test[idx])}): alerts_generate",
    "d +  = 1",
    "print(f\"Generated {alerts_generated} alerts from test set\")",
    "# record metricsrisk_monitor.record_metrics({ \"auc\": roc_auc_score(y_test, y_proba), \"precision\": precision_score(y_test, rf_model.predict(X_test_scaled)), \"recall\": recall_score(y_test, rf_model.predict(X_test_scaled)), \"f1\": f1_score(y_test, rf_model.predict(X_test_scale",
    "d))})",
    "# generate risk reportreport = risk_monitor.generate_risk_repo",
    "r",
    "t()",
    "print(report)",
    "# plot alert summarysummary = risk_monitor.get_alert_summary(hours = 24)fig, axes = plt.subplots(1, 2, figsiz",
    "e = (14, 6))",
    "# alert severity distributio",
    "n",
    "if summary['by_severity']: severities = list(summary['by_severity'].keys()) counts = list(summary['by_severity'].values()) colors = ['darkred' if s == 'CRITICAL' else 'red' if s == 'HIGH' else 'orange' if s == 'MEDIUM' else 'yellow' for s in severities] axes[0].bar(severities, counts, color = colors, alpha = 0.8, edgecolor = 'black', linewidth = 2) axes[0].set_ylabel('Number of Alerts', fontsize = 12, fontweight = 'bold') axes[0].set_title('Alert Distribution by Severity', fontsize = 14, fontweight = 'bold') axes[0].grid(True, alpha = 0.3, axis = 'y')",
    "# top alerted user",
    "s",
    "if summary['top_users']: top_users = summary['top_users'][:10] user_ids = [u['user_id'] for u in top_users] alert_counts = [u['alert_count'] for u in top_users] axes[1].barh(range(len(user_ids)), alert_counts, color = 'red', alpha = 0.7) axes[1].set_yticks(range(len(user_ids))) axes[1].set_yticklabels([f\"User {uid}\" for uid in user_ids], fontsize = 9) axes[1].set_xlabel('Number of Alerts', fontsize = 12, fontweight = 'bold') axes[1].set_title('Top 10 Alerted Users', fontsize = 14, fontweight = 'bold') axes[1].grid(True, alpha = 0.3, axis = 'x')",
    "plt.tight_layout()",
    "plt.savefig(output_dir / \"05_risk_dashboard.png\", dpi = 150, bbox_inches = 'tight')",
    "plt.show()",
    "if HAS_IPYTHON and(output_dir / \"05_risk_dashboard.png\").exists(): display(Image(st",
    "r(output_dir / \"05_risk_dashboard.png\")))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}